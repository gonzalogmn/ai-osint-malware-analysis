import os

import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, Dataset
from transformers import (
    BertForSequenceClassification,
    BertTokenizerFast,
    Trainer,
    TrainingArguments,
)

from config.logger import logger
from src.model.cve_repository import CVERepository


class CVEDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, item):
        encoding = {key: tensor[item] for key, tensor in self.encodings.items()}
        encoding["labels"] = torch.tensor(self.labels[item], dtype=torch.long)
        return encoding


class PredictMalwareTypeWithNLP:
    def __init__(self, input_repository: CVERepository, output_repository: CVERepository):
        self._input_repository = input_repository
        self._output_repository = output_repository
        self._model_dir = "./data/output/nlp/model"

    def __call__(self):
        logger.info("Starting PredictMalwareTypeWithNLP use case...")
        cves = self._input_repository.find_all()
        original_df = pd.DataFrame(cves)
        df = pd.DataFrame(cves, columns=["description", "malware_type"])
        df["full_text"] = df["description"]

        cves_with_malware_type_df = df[
            df["malware_type"].notnull()
            & (df["malware_type"] != "")
            & (df["malware_type"] != "unknown")
        ]

        cves_without_malware_type_df = df[
            (df["malware_type"] == "") | (df["malware_type"] == "unknown")
        ]

        # TODO only for testing
        # cves_with_malware_type_df = cves_with_malware_type_df[:100]
        # cves_without_malware_type_df = cves_without_malware_type_df[:100]

        # Encode the labels
        label_encoder = LabelEncoder()
        cves_with_malware_type_df["label"] = label_encoder.fit_transform(
            cves_with_malware_type_df["malware_type"]
        )

        # Split data into training and testing sets
        train_df, test_df = train_test_split(
            cves_with_malware_type_df, test_size=0.2, random_state=42
        )

        # Load the BERT tokenizer (Fast tokenizer)
        tokenizer = BertTokenizerFast.from_pretrained("bert-base-uncased")

        # Batch tokenization
        train_encodings = tokenizer(
            train_df["full_text"].tolist(),
            add_special_tokens=True,
            max_length=128,
            padding=True,
            truncation=True,
            return_attention_mask=True,
            return_tensors="pt",
        )

        test_encodings = tokenizer(
            test_df["full_text"].tolist(),
            add_special_tokens=True,
            max_length=128,
            padding=True,
            truncation=True,
            return_attention_mask=True,
            return_tensors="pt",
        )

        train_dataset = CVEDataset(train_encodings, train_df["label"].to_numpy())
        test_dataset = CVEDataset(test_encodings, test_df["label"].to_numpy())

        logger.info("Defining training arguments...")
        # Define training arguments with mixed precision
        training_args = TrainingArguments(
            output_dir=self._model_dir,
            num_train_epochs=3,
            per_device_train_batch_size=8,  # Increase batch size
            per_device_eval_batch_size=8,
            warmup_steps=10,
            weight_decay=0.01,
            logging_dir="./logs",
            logging_steps=10,
            evaluation_strategy="epoch",
            fp16=True,  # Enable mixed-precision training
            dataloader_num_workers=4,  # Utilize multiple workers for data loading
            gradient_accumulation_steps=4,  # Simulate larger batch size
        )

        if not os.path.exists(self._model_dir):

            model = BertForSequenceClassification.from_pretrained(
                "bert-base-uncased", num_labels=len(cves_with_malware_type_df["label"].unique())
            )

            logger.info("Creating Trainer instance...")
            # Create a Trainer instance
            trainer = Trainer(
                model=model,
                args=training_args,
                train_dataset=train_dataset,
                eval_dataset=test_dataset,
            )

            logger.info("Training model...")
            trainer.train()
            logger.info("Finished training")

            logger.info("Saving model and tokenizer...")
            model.save_pretrained(self._model_dir)
            tokenizer.save_pretrained(self._model_dir)
            logger.info("Finished model and tokenizer saving")

        else:
            logger.info("Loading the model from disk...")
            model = BertForSequenceClassification.from_pretrained(self._model_dir)
            tokenizer = BertTokenizerFast.from_pretrained(self._model_dir)

        # Create a Trainer instance
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=test_dataset,
        )

        logger.info("Evaluating model...")
        trainer.evaluate()
        logger.info("Finished evaluation")

        CHUNK_SIZE = 10
        total_size = len(cves_without_malware_type_df)
        for start in range(0, total_size, CHUNK_SIZE):
            end = start + CHUNK_SIZE
            logger.info(f"Predicting CVEs {start}-{end} of {total_size}")
            chunk_cves_without_malware_type_df = cves_without_malware_type_df.iloc[start:end]

            cves_without_malware_type_encodings = tokenizer(
                chunk_cves_without_malware_type_df["full_text"].tolist(),
                add_special_tokens=True,
                max_length=128,
                padding=True,
                truncation=True,
                return_attention_mask=True,
                return_tensors="pt",
            )

            cves_without_malware_type_dataset = CVEDataset(
                cves_without_malware_type_encodings,
                torch.zeros(len(chunk_cves_without_malware_type_df)).long(),
            )

            logger.info("Predicting on new data...")
            predictions = trainer.predict(cves_without_malware_type_dataset)
            predicted_labels = predictions.predictions.argmax(axis=1)
            logger.info("Finished predicting on new data")

            predicted_malware_types = []
            for label in predicted_labels:
                try:
                    predicted_malware_types.append(label_encoder.inverse_transform([label])[0])
                except ValueError:
                    predicted_malware_types.append(
                        "unknown"
                    )  # or any placeholder for unseen labels

            # Make a copy of the relevant columns from `cves_with_malware_type_df`
            columns_to_include = list(cves_with_malware_type_df.columns) + [
                "predicted_malware_type"
            ]

            # Create the `output_df` with the predicted labels
            output_df = chunk_cves_without_malware_type_df.copy()
            output_df["predicted_malware_type"] = predicted_malware_types

            # Adjust the `output_df` to include all necessary columns
            output_df = output_df.reindex(columns=columns_to_include, fill_value="")

            logger.info(output_df.head())

            merged_rows = []
            for index, row in output_df.iterrows():
                original_row = original_df[original_df["description"] == row["description"]]

                if not original_row.empty:
                    merged_row = {
                        "cve_id": original_row.iloc[0]["cve_id"],
                        "affected_product": original_row.iloc[0]["affected_product"],
                        "affected_vendor": original_row.iloc[0]["affected_vendor"],
                        "capec_id": original_row.iloc[0]["capec_id"],
                        "date_published": original_row.iloc[0]["date_published"],
                        "description": original_row.iloc[0]["description"],
                        "label": row["label"],
                        "malware_type_x": original_row.iloc[0]["malware_type"],
                        "malware_type_y": row["malware_type"],
                        "predicted_malware_type": row["predicted_malware_type"],
                        "references": original_row.iloc[0]["references"],
                    }

                    merged_rows.append(merged_row)

            merged_df = pd.DataFrame(merged_rows)
            logger.info(
                f"output_df size: {len(output_df)}, original_df size: {len(original_df)}, merged_df size: {len(merged_df)}"
            )

            data_dict = merged_df.to_dict("records")
            for cve in data_dict:
                self._output_repository.save(cve)

        data_dict = cves_with_malware_type_df.to_dict("records")
        for cve in data_dict:
            self._output_repository.save(cve)
