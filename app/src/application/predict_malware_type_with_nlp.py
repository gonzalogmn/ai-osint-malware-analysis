import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, Dataset
from transformers import (
    BertForSequenceClassification,
    BertTokenizer,
    Trainer,
    TrainingArguments,
)

from config import logger
from src.model.cve_repository import CVERepository


class CVEDataset(Dataset):
    def __init__(self, descriptions, labels, tokenizer, max_len):
        self.descriptions = descriptions
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.descriptions)

    def __getitem__(self, item):
        description = str(self.descriptions[item])
        label = self.labels[item]

        encoding = self.tokenizer.encode_plus(
            description,
            add_special_tokens=True,
            max_length=self.max_len,
            return_token_type_ids=False,
            pad_to_max_length=True,
            return_attention_mask=True,
            return_tensors="pt",
        )

        return {
            "description_text": description,
            "input_ids": encoding["input_ids"].flatten(),
            "attention_mask": encoding["attention_mask"].flatten(),
            "labels": torch.tensor(label, dtype=torch.long),
        }


class PredictMalwareTypeWithNLP:
    def __init__(self, input_repository: CVERepository, output_repository: CVERepository):
        self._input_repository = input_repository
        self._output_repository = output_repository

    def __call__(self):
        cves = self._input_repository.find_all()
        df = pd.DataFrame(cves)
        # df["full_text"] = df["description"] + df["reference_text"]
        df["full_text"] = df["description"]

        # original_cves_df = df
        cves_with_malware_type_df = df[df["malware_type"].notnull() & (df["malware_type"] != "")]

        # Encode the labels
        label_encoder = LabelEncoder()
        df["label"] = label_encoder.fit_transform(cves_with_malware_type_df["malware_type"])

        # Split data into training and testing sets
        train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

        # Load the BERT tokenizer
        tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")

        # Create datasets
        train_dataset = CVEDataset(
            descriptions=train_df["full_text"].to_numpy(),
            labels=train_df["label"].to_numpy(),
            tokenizer=tokenizer,
            max_len=128,
        )

        test_dataset = CVEDataset(
            descriptions=test_df["full_text"].to_numpy(),
            labels=test_df["label"].to_numpy(),
            tokenizer=tokenizer,
            max_len=128,
        )

        # Load the BERT model
        model = BertForSequenceClassification.from_pretrained(
            "bert-base-uncased", num_labels=len(df["label"].unique())
        )

        # Define training arguments
        training_args = TrainingArguments(
            output_dir="./data/output/nlp/results",
            num_train_epochs=3,
            per_device_train_batch_size=2,
            per_device_eval_batch_size=2,
            warmup_steps=10,
            weight_decay=0.01,
            logging_dir="./logs",
            logging_steps=10,
            evaluation_strategy="epoch",
        )

        # Create a Trainer instance
        trainer = Trainer(
            model=model, args=training_args, train_dataset=train_dataset, eval_dataset=test_dataset
        )

        # Train the model
        trainer.train()

        # Evaluate the model
        trainer.evaluate()

        # Predict on new data
        predictions = trainer.predict(test_dataset)
        predicted_labels = predictions.predictions.argmax(axis=1)
        predicted_malware_types = label_encoder.inverse_transform(predicted_labels)

        logger.info(predicted_malware_types)
